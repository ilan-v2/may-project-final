{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b67e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8884d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-seg.pt to 'yolo11s-seg.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19.7M/19.7M [00:00<00:00, 28.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = ultralytics.YOLO('yolo11s-seg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a382adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 125.0ms\n",
      "1: 480x640 (no detections), 125.0ms\n",
      "2: 480x640 (no detections), 125.0ms\n",
      "3: 480x640 (no detections), 125.0ms\n",
      "Speed: 1.7ms preprocess, 125.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "feed_examples = ['8199','8200','8211', '8206']\n",
    "feed_paths = [f'../static/data/img/{f}.jpeg' for f in feed_examples]\n",
    "\n",
    "def load_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    # flip image 180 degrees\n",
    "    img = img.rotate(180)\n",
    "    # zoom on the 25% top left corner\n",
    "    img = img.crop((0, 0, img.width // 2, img.height // 2))\n",
    "    return img\n",
    "\n",
    "imgs = [load_image(path) for path in feed_paths]\n",
    "results = model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35cac3c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) :-1: error: (-5:Bad argument) in function 'findContours'\n> Overload resolution failed:\n>  - image is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'image'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m imgs = [Image.open(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m feed_paths]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 2) find all contours\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m cnts = [\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindContours\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRETR_EXTERNAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHAIN_APPROX_SIMPLE\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs]\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# plot contours on the original image, side by side with the original image\u001b[39;00m\n\u001b[32m     20\u001b[39m plt.figure(figsize=(\u001b[32m15\u001b[39m, \u001b[32m10\u001b[39m))\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.12.0) :-1: error: (-5:Bad argument) in function 'findContours'\n> Overload resolution failed:\n>  - image is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'image'\n"
     ]
    }
   ],
   "source": [
    "# 1) load & preprocess\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "    # flip image 180 degrees\n",
    "    edges = cv2.rotate(edges, cv2.ROTATE_180)\n",
    "    # focus on the top left corner\n",
    "    edges = edges[:edges.shape[0] // 2, :edges.shape[1] // 2]\n",
    "    # dilate to connect edges\n",
    "    # edges = cv2.dilate(edges, None)\n",
    "    return edges\n",
    "\n",
    "imgs = [Image.open(path) for path in feed_paths]\n",
    "# 2) find all contours\n",
    "cnts = [cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) for img in imgs]\n",
    "\n",
    "# plot contours on the original image, side by side with the original image\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, (img, cnt) in enumerate(zip(imgs, cnts)):\n",
    "    plt.subplot(2, len(imgs), i + 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f'Image {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, len(imgs), i + 1 + len(imgs))\n",
    "    img_contours = cv2.drawContours(img.copy(), cnt[0], -1, (0, 255, 0), 2)\n",
    "    plt.imshow(img_contours)\n",
    "    plt.title(f'Contours {i+1}')\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e40d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: tensor([[0.0025, 0.0033, 0.0023, 0.0007, 0.0006, 0.0052, 0.0004, 0.0650, 0.0035, 0.1959, 0.0279, 0.1909, 0.0638, 0.0689, 0.0229, 0.0350, 0.0151]])\n",
      "data: tensor([[[4.1426e+02, 8.4240e+01, 2.4584e-03],\n",
      "         [4.7984e+02, 4.5436e+01, 3.2935e-03],\n",
      "         [3.6095e+02, 3.7871e+01, 2.3173e-03],\n",
      "         [5.7480e+02, 3.0479e+01, 6.8906e-04],\n",
      "         [2.4025e+02, 8.3103e+00, 5.9704e-04],\n",
      "         [6.6137e+02, 7.3823e+01, 5.1627e-03],\n",
      "         [1.3799e+02, 3.0369e+01, 3.7136e-04],\n",
      "         [7.7719e+02, 3.5977e+01, 6.4980e-02],\n",
      "         [2.2236e+02, 0.0000e+00, 3.4688e-03],\n",
      "         [7.3908e+02, 1.7548e+01, 1.9588e-01],\n",
      "         [5.0502e+02, 0.0000e+00, 2.7860e-02],\n",
      "         [5.8546e+02, 1.6116e+02, 1.9095e-01],\n",
      "         [2.1897e+02, 1.4934e+02, 6.3817e-02],\n",
      "         [6.3276e+02, 3.5219e+02, 6.8879e-02],\n",
      "         [2.1375e+02, 3.3862e+02, 2.2869e-02],\n",
      "         [5.7836e+02, 2.9745e+02, 3.5015e-02],\n",
      "         [3.0549e+02, 2.9785e+02, 1.5058e-02]]])\n",
      "has_visible: True\n",
      "orig_shape: (960, 1280)\n",
      "shape: torch.Size([1, 17, 3])\n",
      "xy: tensor([[[414.2628,  84.2403],\n",
      "         [479.8369,  45.4361],\n",
      "         [360.9546,  37.8706],\n",
      "         [574.8040,  30.4785],\n",
      "         [240.2458,   8.3103],\n",
      "         [661.3734,  73.8228],\n",
      "         [137.9902,  30.3687],\n",
      "         [777.1882,  35.9767],\n",
      "         [222.3622,   0.0000],\n",
      "         [739.0753,  17.5478],\n",
      "         [505.0166,   0.0000],\n",
      "         [585.4559, 161.1571],\n",
      "         [218.9693, 149.3405],\n",
      "         [632.7581, 352.1937],\n",
      "         [213.7486, 338.6227],\n",
      "         [578.3627, 297.4509],\n",
      "         [305.4879, 297.8505]]])\n",
      "xyn: tensor([[[0.3236, 0.0878],\n",
      "         [0.3749, 0.0473],\n",
      "         [0.2820, 0.0394],\n",
      "         [0.4491, 0.0317],\n",
      "         [0.1877, 0.0087],\n",
      "         [0.5167, 0.0769],\n",
      "         [0.1078, 0.0316],\n",
      "         [0.6072, 0.0375],\n",
      "         [0.1737, 0.0000],\n",
      "         [0.5774, 0.0183],\n",
      "         [0.3945, 0.0000],\n",
      "         [0.4574, 0.1679],\n",
      "         [0.1711, 0.1556],\n",
      "         [0.4943, 0.3669],\n",
      "         [0.1670, 0.3527],\n",
      "         [0.4518, 0.3098],\n",
      "         [0.2387, 0.3103]]])\n",
      "ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: tensor([], size=(0, 17))\n",
      "data: tensor([], size=(0, 17, 3))\n",
      "has_visible: True\n",
      "orig_shape: (960, 1280)\n",
      "shape: torch.Size([0, 17, 3])\n",
      "xy: tensor([], size=(0, 17, 2))\n",
      "xyn: tensor([], size=(0, 17, 2))\n"
     ]
    }
   ],
   "source": [
    "# plot keypoint matching on images\n",
    "from PIL import Image\n",
    "import cv2\n",
    "def load_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = Image.fromarray(img).convert('RGB')\n",
    "    return img\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
